{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46fb935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b0781b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10_CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(8)\n",
    "\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.relu(F.max_pool2d(self.batchnorm1(self.conv1(x)), kernel_size=2, stride=2))\n",
    "        x = torch.relu(F.max_pool2d(self.batchnorm2(self.conv2(x)), kernel_size=2, stride=2))\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2c08020",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "    #                      (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "data_dir = \"./data\"\n",
    "train_ds = datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform_test)\n",
    "test_ds  = datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=0)\n",
    "test_loader  = DataLoader(test_ds, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0758b7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: running_val_loss=tensor(224.8092), running_train_loss=tensor(1285.4264, grad_fn=<AddBackward0>)\n",
      "2: running_val_loss=tensor(218.5477), running_train_loss=tensor(1042.9135, grad_fn=<AddBackward0>)\n",
      "3: running_val_loss=tensor(279.1239), running_train_loss=tensor(944.3522, grad_fn=<AddBackward0>)\n",
      "4: running_val_loss=tensor(186.5254), running_train_loss=tensor(882.8271, grad_fn=<AddBackward0>)\n",
      "5: running_val_loss=tensor(261.0594), running_train_loss=tensor(847.1922, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "model = CIFAR10_CNN()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for i in range(1, epochs + 1):\n",
    "\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = model(images)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss\n",
    "\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            preds = model(images)\n",
    "            loss = loss_fn(preds, labels)\n",
    "\n",
    "            running_val_loss += loss\n",
    "\n",
    "    print(f\"{i}: {running_val_loss=}, {running_train_loss=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a06d295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './models/cifar_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38a9e3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 131072])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight.view(1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "79b6b9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WatermarkExtractor(nn.Module):\n",
    "\n",
    "    def __init__(self, n_params, n_bits):\n",
    "        super().__init__()\n",
    "        self.X = nn.Parameter(torch.randn(n_params, n_bits) * 0.1)\n",
    "\n",
    "    def forward(self, layer_weight: torch.Tensor):\n",
    "\n",
    "        flattened = layer_weight.view(1, -1)\n",
    "        probs = torch.sigmoid(torch.matmul(flattened, self.X))\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9c61b2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def watermark_loss(extractor: WatermarkExtractor, weights: torch.Tensor, target_bits: torch.Tensor):\n",
    "\n",
    "    probs = extractor(weights)\n",
    "    assert probs.shape == target_bits.shape\n",
    "\n",
    "    target_bits = target_bits.float()\n",
    "\n",
    "    return F.binary_cross_entropy(probs, target_bits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "131859ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_bits = torch.tensor([[1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1]])\n",
    "target_bits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1d7283b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = model.fc1.weight.shape\n",
    "wm = WatermarkExtractor(r*c, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e05be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.8869643211364746\n",
      "1: 0.7162444591522217\n",
      "2: 0.5824374556541443\n",
      "3: 0.4786510169506073\n",
      "4: 0.39871537685394287\n",
      "5: 0.33732837438583374\n",
      "6: 0.29002583026885986\n",
      "7: 0.2531982660293579\n",
      "8: 0.22408445179462433\n",
      "9: 0.20066756010055542\n",
      "10: 0.18150900304317474\n",
      "11: 0.16558396816253662\n",
      "12: 0.15215860307216644\n",
      "13: 0.14069890975952148\n",
      "14: 0.13080903887748718\n",
      "15: 0.12219193577766418\n",
      "16: 0.11461876332759857\n",
      "17: 0.10791292786598206\n",
      "18: 0.10193528234958649\n",
      "19: 0.09657395631074905\n",
      "20: 0.09173943847417831\n",
      "21: 0.0873580127954483\n",
      "22: 0.08336956799030304\n",
      "23: 0.07972396165132523\n",
      "24: 0.07637917250394821\n",
      "25: 0.07329951971769333\n",
      "26: 0.07045510411262512\n",
      "27: 0.06782010197639465\n",
      "28: 0.06537248194217682\n",
      "29: 0.06309293210506439\n",
      "30: 0.060964807868003845\n",
      "31: 0.05897374451160431\n",
      "32: 0.057107165455818176\n",
      "33: 0.05535336211323738\n",
      "34: 0.05370289087295532\n",
      "35: 0.05214671790599823\n",
      "36: 0.05067726597189903\n",
      "37: 0.04928745701909065\n",
      "38: 0.04797092080116272\n",
      "39: 0.046721864491701126\n",
      "40: 0.04553564265370369\n",
      "41: 0.04440752789378166\n",
      "42: 0.04333338513970375\n",
      "43: 0.042309392243623734\n",
      "44: 0.0413321815431118\n",
      "45: 0.04039861634373665\n",
      "46: 0.0395059660077095\n",
      "47: 0.03865129500627518\n",
      "48: 0.03783262148499489\n",
      "49: 0.03704749792814255\n",
      "50: 0.03629407286643982\n",
      "51: 0.03557045757770538\n",
      "52: 0.03487468510866165\n",
      "53: 0.03420547395944595\n",
      "54: 0.033561088144779205\n",
      "55: 0.03294052556157112\n",
      "56: 0.03234212473034859\n",
      "57: 0.03176509216427803\n",
      "58: 0.03120788186788559\n",
      "59: 0.030669907107949257\n",
      "60: 0.030149836093187332\n",
      "61: 0.02964722365140915\n",
      "62: 0.029160697013139725\n",
      "63: 0.028689803555607796\n",
      "64: 0.02823380008339882\n",
      "65: 0.02779201790690422\n",
      "66: 0.027363676577806473\n",
      "67: 0.026948215439915657\n",
      "68: 0.02654511108994484\n",
      "69: 0.0261538028717041\n",
      "70: 0.025773704051971436\n",
      "71: 0.02540443278849125\n",
      "72: 0.02504565194249153\n",
      "73: 0.024696683511137962\n",
      "74: 0.024357281625270844\n",
      "75: 0.024027066305279732\n",
      "76: 0.02370552346110344\n",
      "77: 0.023392323404550552\n",
      "78: 0.02308741956949234\n",
      "79: 0.02279023267328739\n",
      "80: 0.022500593215227127\n",
      "81: 0.022218216210603714\n",
      "82: 0.021942630410194397\n",
      "83: 0.021673845127224922\n",
      "84: 0.021411556750535965\n",
      "85: 0.021155497059226036\n",
      "86: 0.020905334502458572\n",
      "87: 0.020661072805523872\n",
      "88: 0.02042243629693985\n",
      "89: 0.02018923871219158\n",
      "90: 0.01996120996773243\n",
      "91: 0.019738197326660156\n",
      "92: 0.01952020451426506\n",
      "93: 0.019306892529129982\n",
      "94: 0.019098151475191116\n",
      "95: 0.018893856555223465\n",
      "96: 0.018693862482905388\n",
      "97: 0.018498070538043976\n",
      "98: 0.018306326121091843\n",
      "99: 0.01811840757727623\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fc1_weights = model.fc1.weight\n",
    "\n",
    "extractor_optimzer = optim.SGD(wm.parameters(), lr=0.1)\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    loss = watermark_loss(wm, fc1_weights, target_bits)\n",
    "    \n",
    "    print(f\"{i}: {loss}\")\n",
    "\n",
    "    extractor_optimzer.zero_grad()\n",
    "    loss.backward()\n",
    "    extractor_optimzer.step()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "964e68c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1]])\n",
      "tensor([[0.2509, 0.4852, 0.5434, 0.7013, 0.3283, 0.8512, 0.2311, 0.7508, 0.7840,\n",
      "         0.6704, 0.5247, 0.5230, 0.3145, 0.7994, 0.4796, 0.4615]],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False,  True,  True,  True, False, False,  True, False,  True,\n",
       "         False, False, False,  True, False, False]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = CIFAR10_CNN()\n",
    "fc1_model2_weights = model2.fc1.weight\n",
    "\n",
    "res = wm(fc1_model2_weights)\n",
    "print(target_bits)\n",
    "print(res)\n",
    "(res >= 0.5).int() == target_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890d3fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
